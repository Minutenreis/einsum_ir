
\section{Scaling beyond 2 Nodes}

While the previously discussed Master-Worker approach to parallelism worked suitably well for 2 compute nodes, the same is not true for scaling the number of compute nodes.
In the Master-Worker approach one node had to send all the data to all the other nodes for their respective computations.
This results in very unbalanced workloads for higher node counts, since the Master thread is involved in all computation while each worker is only involved in one.
It also necessitated all the data to end up at the Master node after each operation.
But the topic of this work was accelerating whole Einsum trees instead of single binary contractions.
In Einsum trees we can let data be kept distributed all the way up to the root.

To keep the data distributed I instead propose algorithms where all nodes have the same responsibility.
This makes scaling to more nodes easier to express, as each node just gets a smaller part of the total work and keeps total communication work shared between all nodes.
I specifically advocate for algorithms communicating in a ring, where each node only communicates with one precursor and one successor.
This enables more local communication between nodes in a cluster setting.

% Vorteile
% * Kommunikation wird lokal gehalten (gerade in nicht voll verbundenen größeren Clustern relevant)
% * bei m/n kann ein buffer eingespart werden (und wahrscheinlich auch bei k)
% * die Kommunikation is einfacher auszudrücken im Code (da nur 2 weitere MPI Ränge relevant sind statt alle)