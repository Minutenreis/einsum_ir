from tvm_einsum_tree_parser import *
import sys
import argparse

tvm_header = """import tvm
import tvm.auto_scheduler
import tvm_helper
import argparse"""

tvm_runner = """
if __name__=="__main__":
  args = tvm_helper.parse_args()

  target = tvm.target.Target( tvm_helper.cpu_to_llvm( args.cpu ) )
  hardware_params = tvm.auto_scheduler.HardwareParams( target = target )
  dtype = args.dtype
  num_measure_trials = args.num_measure_trials
  timeout = args.timeout
  log_file = args.log_file

  einsum_str = "{einsum_str}"
  func = einsum_tree
  sizes = {dimension_sizes}

  tvm_helper.run_all( einsum_str,
                      func,
                      sizes,
                      dtype,
                      hardware_params,
                      target,
                      num_measure_trials,
                      timeout,
                      log_file )"""

def parser_einsum(input_einsum_tree):
    input_einsum_array = []
    input_tensor_array = []
    all_input_tensors = []
    later_input_tensors = []

    print( "##" )
    print( "# Note: This script was automatically generated by tvm_from_tree.py." )
    print( "#")
    print( "# input_string: "+ input_einsum_tree )
    print( "##" )

    pattern = r'(\[(\w,?)+\])\s*->\s*(\[(\w,?)+\])'

    input_einsum_tree = re.sub(pattern, remove_transpositions, input_einsum_tree)

    dim_count = count_unique_elements(input_einsum_tree)

    print("@tvm.auto_scheduler.register_workload")
    if check_string(input_einsum_tree):
        print(f'def einsum_tree( ' + ", ".join(f"dim_{i}" for i in range(dim_count[0])) + ', dtype):')
    else:
        print(f'def einsum_tree( ' + ", ".join(f"dim_{chr(i)}" for i in range(97, (97+dim_count[0]))) + ', dtype):')
    print_single_expressions(input_einsum_tree, input_einsum_array, later_input_tensors)

    for i in input_einsum_array:
        input_tensor_array.append(i.split('->')[0])


    for i in input_tensor_array:
        split_index = i.find('],[')
        all_input_tensors.append(i[:split_index+1])
        all_input_tensors.append(i[split_index+2:])

    # merge all_input_tensors and later_input_tensors
    all_input_tensors = all_input_tensors + later_input_tensors

    input_arrays = generate_tvm_expressions_placeholder(all_input_tensors)

    print()

    generate_tvm_reduce_axis(input_einsum_tree)

    print()

    generate_tvm_compute(input_einsum_tree, input_arrays)

    return all_input_tensors


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Parse einsum tree and generate TVM code')
    parser.add_argument('--einsum_tree', type=str, required=True,
                        help='Input einsum tree; example: "[[8,4],[7,3,8]->[7,3,4]],[[[[6,3,7]->[3,6,7]],[[5,1,6]->[1,5,6]]->[1,2,5,7]],[0,5]->[0,1,2,7]]->[0,1,2,3,4]"')
    parser.add_argument('--dim_sizes', type=str, required=True,
                        help='Comma-separated list of dimension sizes; example: "40,40,20,20,6,6,6,6,4,4,4,4"')
    args = parser.parse_args()

    print( tvm_header )

    input_tensors = parser_einsum(args.einsum_tree)

    # assemble einsum string
    input_tensors = [i.strip("[]").split(',') for i in input_tensors]
    output_tensor = args.einsum_tree.split('->')[-1].strip("[]").split(',')

    def get_dim_char(i):
        i = int(i)
        if i < 26:
            return chr(65 + i)  # A-Z
        elif i < 52:
            return chr(97 + (i - 26))  # a-z
        else:
            return chr(256 + (i - 52))

    input_tensors = [[get_dim_char(i) for i in j] for j in input_tensors]
    output_tensor = [get_dim_char(i) for i in output_tensor]

    einsum_str = ",".join(["".join(i) for i in input_tensors]) + "->" + "".join(output_tensor)

    # convert sizes to tuple
    args.dim_sizes = tuple([int(i) for i in args.dim_sizes.split(',')])

    print( tvm_runner.format( einsum_str      = einsum_str,
                              dimension_sizes = args.dim_sizes ) )