import tvm
import tvm.auto_scheduler
import tvm_helper
import argparse
##
# Note: This script was automatically generated by tvm_from_tree.py.
#
# input_string: [[[8,0,9,4]->[0,9,4,8]],[[2,8,6,9]->[6,2,9,8]]->[6,2,0,4,8]],[[[[3,2,1,0]->[3,1,2,0]],[[1,5]->[5,1]]->[5,3,2,0]],[[3,7]->[7,3]]->[7,5,2,0]]->[7,6,5,4,8]
##
@tvm.auto_scheduler.register_workload
def einsum_tree( dim_0, dim_1, dim_2, dim_3, dim_4, dim_5, dim_6, dim_7, dim_8, dim_9, dtype):
  tensor_3_2_1_0 = tvm.te.placeholder((dim_3, dim_2, dim_1, dim_0), name='tensor_3_2_1_0', dtype=dtype)
  tensor_1_5 = tvm.te.placeholder((dim_1, dim_5), name='tensor_1_5', dtype=dtype)
  tensor_8_0_9_4 = tvm.te.placeholder((dim_8, dim_0, dim_9, dim_4), name='tensor_8_0_9_4', dtype=dtype)
  tensor_2_8_6_9 = tvm.te.placeholder((dim_2, dim_8, dim_6, dim_9), name='tensor_2_8_6_9', dtype=dtype)
  tensor_3_7 = tvm.te.placeholder((dim_3, dim_7), name='tensor_3_7', dtype=dtype)

  tmp_0 = tvm.te.reduce_axis((0, dim_0), name='tmp_0')
  tmp_9 = tvm.te.reduce_axis((0, dim_9), name='tmp_9')
  tmp_1 = tvm.te.reduce_axis((0, dim_1), name='tmp_1')
  tmp_2 = tvm.te.reduce_axis((0, dim_2), name='tmp_2')
  tmp_3 = tvm.te.reduce_axis((0, dim_3), name='tmp_3')

  tensor_5_3_2_0 = tvm.te.compute( (dim_5, dim_3, dim_2, dim_0), lambda tmp_5, tmp_3, tmp_2, tmp_0: tvm.te.sum( tensor_3_2_1_0[ tmp_3, tmp_2, tmp_1, tmp_0 ] * tensor_1_5[ tmp_1, tmp_5 ] , axis=[ tmp_1 ]), name='tensor_5_3_2_0' )
  tensor_7_5_2_0 = tvm.te.compute( (dim_7, dim_5, dim_2, dim_0), lambda tmp_7, tmp_5, tmp_2, tmp_0: tvm.te.sum( tensor_5_3_2_0[ tmp_5, tmp_3, tmp_2, tmp_0 ] * tensor_3_7[ tmp_3, tmp_7 ] , axis=[ tmp_3 ]), name='tensor_7_5_2_0' )
  tensor_6_2_0_4_8 = tvm.te.compute( (dim_6, dim_2, dim_0, dim_4, dim_8), lambda tmp_6, tmp_2, tmp_0, tmp_4, tmp_8: tvm.te.sum( tensor_8_0_9_4[ tmp_8, tmp_0, tmp_9, tmp_4 ] * tensor_2_8_6_9[ tmp_2, tmp_8, tmp_6, tmp_9 ] , axis=[ tmp_9 ]), name='tensor_6_2_0_4_8' )
  tensor_7_6_5_4_8 = tvm.te.compute( (dim_7, dim_6, dim_5, dim_4, dim_8), lambda tmp_7, tmp_6, tmp_5, tmp_4, tmp_8: tvm.te.sum( tensor_6_2_0_4_8[ tmp_6, tmp_2, tmp_0, tmp_4, tmp_8 ] * tensor_7_5_2_0[ tmp_7, tmp_5, tmp_2, tmp_0 ] , axis=[ tmp_2, tmp_0 ]), name='tensor_7_6_5_4_8' )

  return [ tensor_3_2_1_0, tensor_1_5, tensor_8_0_9_4, tensor_2_8_6_9, tensor_3_7, tensor_7_6_5_4_8 ]

if __name__=="__main__":
  args = tvm_helper.parse_args()

  target = tvm.target.Target( tvm_helper.cpu_to_llvm( args.cpu ) )
  hardware_params = tvm.auto_scheduler.HardwareParams( target = target )
  dtype = args.dtype
  num_measure_trials = args.num_measure_trials
  timeout = args.timeout
  log_file = args.log_file

  einsum_str = "DCBA,BF,IAJE,CIGJ,DH->HGFEI"
  func = einsum_tree
  sizes = (24, 48, 12, 56, 32, 64, 8, 84, 8, 72)

  tvm_helper.run_all( einsum_str,
                      func,
                      sizes,
                      dtype,
                      hardware_params,
                      target,
                      num_measure_trials,
                      timeout,
                      log_file )
