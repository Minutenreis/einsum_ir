Tensor Decompositions
=====================

Tensor Train Decomposition
--------------------------
Tensor train (TT) decomposition of the COIL-100 dataset.
The script ``tt.py`` was used to generate the decomposition.
The config ``tt.cfg`` contains a corresponding einsum expression and contraction path for performance benchmarking. It was derived from the obtained output.
The config ``tt_et.cfg`` contains a respective einsum tree optimized by the simple internal heuristic of einsum_ir (version #c600e8a).
The TVM setting ``tt_tvm.py`` was generated by converting the internal einsum tree from einsum_ir (version #de7d468).

.. code-block:: bash

   python tt.py 2>&1 | tee tt.log
   python ../tools/tvm_from_tree.py --einsum_tree "[[8,4],[7,3,8]->[7,3,4]],[[[[6,2,7]->[2,6,7]],[[5,1,6]->[1,5,6]]->[1,2,5,7]],[0,5]->[0,1,2,7]]->[0,1,2,3,4]" --dim_sizes "100,72,128,128,3,71,305,32,3" > tt_tvm.py

Fully Connected Tensor Network
------------------------------
Fully connected tensor network (FCTN) decomposition in https://doi.org/10.1609/aaai.v35i12.17321 for the hyperspectral video (HSV) with all ranks set to 8.
The script ``fctn.py`` was used to compute the contraction path.
The config ``fctn.cfg`` contains a corresponding einsum expression and contraction path for performance benchmarking. It was derived from the obtained output.
The config ``fctn_et.cfg`` contains a respective einsum tree optimized by the simple internal heuristic of einsum_ir (version #c600e8a).
The TVM setting ``fctn_tvm.py`` was generated by converting the internal einsum tree from einsum_ir (version #de7d468).

.. code-block:: bash

   python fctn.py 2>&1 | tee fctn.log
   python ../tools/tvm_from_tree.py --einsum_tree "[[[[3,6,8,9]->[8,6,9,3]],[[2,5,7,9]->[7,5,2,9]]->[7,8,5,6,2,3]],[0,4,5,6]->[0,4,7,8,2,3]],[1,4,7,8]->[0,1,2,3]" --dim_sizes "60,60,20,20,8,8,8,8,8,8" > fctn_tvm.py

Tensor Wheel Decomposition
--------------------------
Tensor wheel decomposition in https://dl.acm.org/doi/10.5555/3600270.3602228 for the hyperspectral video (HSV) with R1 = R2 = R3 = R4 = 6 and  L1 = L2 = L3 = L4 = 4.
The script ``tw.py`` was used to compute the contraction path.
The config ``tw.cfg`` contains a corresponding einsum expression and contraction path for performance benchmarking. It was derived from the obtained output.
The config ``tw_et.cfg`` contains a respective einsum tree optimized by the simple internal heuristic of einsum_ir (version #c600e8a).
The TVM setting ``tw_tvm.py`` was generated by converting the internal einsum tree from einsum_ir (version #de7d468).

.. code-block:: bash

   python tw.py 2>&1 | tee tw.log
   python ../tools/tvm_from_tree.py --einsum_tree "[[[[[3,7,4,11]->[4,11,7,3]],[[2,6,7,10]->[6,10,2,7]]->[6,4,10,11,2,3]],[[8,9,10,11]->[9,8,10,11]]->[9,6,8,4,2,3]],[[0,4,5,8]->[0,5,8,4]]->[0,9,5,6,2,3]],[[1,5,6,9]->[1,9,5,6]]->[0,1,2,3]" --dim_sizes "40,40,20,20,6,6,6,6,4,4,4,4" > tw_tvm.py

Generalized model based on Tucker decomposition and Tensor Ring decomposition
-----------------------------------------------------------------------------
Tensor decomposition in https://dl.acm.org/doi/10.1145/3366423.3380188 for the n-ary relational dataset JF17K-4.
The script ``getd.py`` was used to compute the contraction path.
The config ``getd.cfg`` contains a corresponding einsum expression and contraction path for performance benchmarking. It was derived from the obtained output.
The config ``getd_et.cfg`` contains a respective einsum tree optimized by the simple internal heuristic of einsum_ir (version #c600e8a).
The TVM setting ``getd_tvm.py`` was generated by converting the internal einsum tree from einsum_ir (version #de7d468).

.. code-block:: bash

   python getd.py 2>&1 | tee getd.log
   python ../tools/tvm_from_tree.py --einsum_tree "[[[4,9,0]->[0,4,9]],[[[0,5,1]->[5,1,0]],[[1,6,2]->[6,2,1]]->[5,6,2,0]]->[5,6,2,4,9]],[[[3,8,4]->[8,3,4]],[[2,7,3]->[7,2,3]]->[7,2,8,4]]->[5,6,7,8,9]" --dim_sizes "40,40,40,40,40,25,25,25,25,25" > getd_tvm.py